{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_text</th>\n",
       "      <th>job_description_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SummaryHighly motivated Sales Associate with e...</td>\n",
       "      <td>Net2Source Inc. is an award-winning total work...</td>\n",
       "      <td>No Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Professional SummaryCurrently working with Cat...</td>\n",
       "      <td>At Salas OBrien we tell our clients that were ...</td>\n",
       "      <td>No Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SummaryI started my construction career in Jun...</td>\n",
       "      <td>Schweitzer Engineering Laboratories (SEL) Infr...</td>\n",
       "      <td>No Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SummaryCertified Electrical Foremanwith thirte...</td>\n",
       "      <td>Mizick Miller &amp; Company, Inc. is looking for a...</td>\n",
       "      <td>No Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SummaryWith extensive experience in business/r...</td>\n",
       "      <td>Life at Capgemini\\nCapgemini supports all aspe...</td>\n",
       "      <td>No Fit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         resume_text  \\\n",
       "0  SummaryHighly motivated Sales Associate with e...   \n",
       "1  Professional SummaryCurrently working with Cat...   \n",
       "2  SummaryI started my construction career in Jun...   \n",
       "3  SummaryCertified Electrical Foremanwith thirte...   \n",
       "4  SummaryWith extensive experience in business/r...   \n",
       "\n",
       "                                job_description_text   label  \n",
       "0  Net2Source Inc. is an award-winning total work...  No Fit  \n",
       "1  At Salas OBrien we tell our clients that were ...  No Fit  \n",
       "2  Schweitzer Engineering Laboratories (SEL) Infr...  No Fit  \n",
       "3  Mizick Miller & Company, Inc. is looking for a...  No Fit  \n",
       "4  Life at Capgemini\\nCapgemini supports all aspe...  No Fit  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "125/125 [==============================] - 11s 68ms/step - loss: 0.9935 - accuracy: 0.5222 - val_loss: 0.8410 - val_accuracy: 0.5786\n",
      "Epoch 2/30\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.7910 - accuracy: 0.6289 - val_loss: 0.7779 - val_accuracy: 0.6106\n",
      "Epoch 3/30\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 0.7142 - accuracy: 0.6712 - val_loss: 0.7641 - val_accuracy: 0.6256\n",
      "Epoch 4/30\n",
      "125/125 [==============================] - 9s 71ms/step - loss: 0.6675 - accuracy: 0.6995 - val_loss: 0.7456 - val_accuracy: 0.6557\n",
      "Epoch 5/30\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 0.6098 - accuracy: 0.7248 - val_loss: 0.7483 - val_accuracy: 0.6777\n",
      "Epoch 6/30\n",
      "125/125 [==============================] - 8s 62ms/step - loss: 0.5628 - accuracy: 0.7536 - val_loss: 0.6907 - val_accuracy: 0.6757\n",
      "Epoch 7/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 0.5233 - accuracy: 0.7754 - val_loss: 0.6800 - val_accuracy: 0.6937\n",
      "Epoch 8/30\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 0.4760 - accuracy: 0.7991 - val_loss: 0.6836 - val_accuracy: 0.7097\n",
      "Epoch 9/30\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.4300 - accuracy: 0.8207 - val_loss: 0.6654 - val_accuracy: 0.7267\n",
      "Epoch 10/30\n",
      "125/125 [==============================] - 8s 62ms/step - loss: 0.4115 - accuracy: 0.8315 - val_loss: 0.6719 - val_accuracy: 0.7317\n",
      "Epoch 11/30\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 0.3777 - accuracy: 0.8402 - val_loss: 0.6875 - val_accuracy: 0.7427\n",
      "Epoch 12/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 0.3506 - accuracy: 0.8545 - val_loss: 0.7085 - val_accuracy: 0.7518\n",
      "Epoch 13/30\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 0.3290 - accuracy: 0.8608 - val_loss: 0.7116 - val_accuracy: 0.7578\n",
      "Epoch 14/30\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 0.3168 - accuracy: 0.8623 - val_loss: 0.7165 - val_accuracy: 0.7588\n",
      "Epoch 15/30\n",
      "125/125 [==============================] - 8s 66ms/step - loss: 0.2985 - accuracy: 0.8785 - val_loss: 0.7521 - val_accuracy: 0.7708\n",
      "Epoch 16/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 0.2895 - accuracy: 0.8830 - val_loss: 0.7145 - val_accuracy: 0.7658\n",
      "Epoch 17/30\n",
      "125/125 [==============================] - 8s 67ms/step - loss: 0.2648 - accuracy: 0.8886 - val_loss: 0.7363 - val_accuracy: 0.7698\n",
      "Epoch 18/30\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 0.2616 - accuracy: 0.8938 - val_loss: 0.7748 - val_accuracy: 0.7688\n",
      "Epoch 19/30\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.2490 - accuracy: 0.9038 - val_loss: 0.8168 - val_accuracy: 0.7648\n",
      "Epoch 20/30\n",
      "125/125 [==============================] - 8s 61ms/step - loss: 0.2419 - accuracy: 0.9011 - val_loss: 0.7645 - val_accuracy: 0.7698\n",
      "Epoch 21/30\n",
      "125/125 [==============================] - 8s 62ms/step - loss: 0.2258 - accuracy: 0.9083 - val_loss: 0.8680 - val_accuracy: 0.7708\n",
      "Epoch 22/30\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.2234 - accuracy: 0.9091 - val_loss: 0.8477 - val_accuracy: 0.7798\n",
      "Epoch 23/30\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.2121 - accuracy: 0.9184 - val_loss: 0.8338 - val_accuracy: 0.7798\n",
      "Epoch 24/30\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.2038 - accuracy: 0.9186 - val_loss: 0.9341 - val_accuracy: 0.7628\n",
      "Epoch 25/30\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 0.1911 - accuracy: 0.9274 - val_loss: 0.9642 - val_accuracy: 0.7648\n",
      "Epoch 26/30\n",
      "125/125 [==============================] - 8s 62ms/step - loss: 0.1998 - accuracy: 0.9191 - val_loss: 0.9618 - val_accuracy: 0.7638\n",
      "Epoch 27/30\n",
      "125/125 [==============================] - 8s 62ms/step - loss: 0.1866 - accuracy: 0.9274 - val_loss: 1.0054 - val_accuracy: 0.7688\n",
      "Epoch 28/30\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.1674 - accuracy: 0.9364 - val_loss: 1.0626 - val_accuracy: 0.7798\n",
      "Epoch 29/30\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.1612 - accuracy: 0.9354 - val_loss: 0.9904 - val_accuracy: 0.7848\n",
      "Epoch 30/30\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.1661 - accuracy: 0.9301 - val_loss: 1.0711 - val_accuracy: 0.7708\n",
      "40/40 [==============================] - 1s 15ms/step - loss: 1.2441 - accuracy: 0.7718\n",
      "Test Accuracy: 0.7718174457550049\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['resume_text', 'job_description_text']], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(pd.concat([X_train['resume_text'], X_train['job_description_text']]))\n",
    "\n",
    "X_train_resume = tokenizer.texts_to_sequences(X_train['resume_text'])\n",
    "X_train_job_desc = tokenizer.texts_to_sequences(X_train['job_description_text'])\n",
    "X_test_resume = tokenizer.texts_to_sequences(X_test['resume_text'])\n",
    "X_test_job_desc = tokenizer.texts_to_sequences(X_test['job_description_text'])\n",
    "\n",
    "max_len = 100\n",
    "X_train_resume = pad_sequences(X_train_resume, maxlen=max_len)\n",
    "X_train_job_desc = pad_sequences(X_train_job_desc, maxlen=max_len)\n",
    "X_test_resume = pad_sequences(X_test_resume, maxlen=max_len)\n",
    "X_test_job_desc = pad_sequences(X_test_job_desc, maxlen=max_len)\n",
    "\n",
    "input_resume = Input(shape=(max_len,))\n",
    "input_job_desc = Input(shape=(max_len,))\n",
    "\n",
    "embedding = Embedding(input_dim=10000, output_dim=128, input_length=max_len)\n",
    "\n",
    "encoded_resume = embedding(input_resume)\n",
    "encoded_job_desc = embedding(input_job_desc)\n",
    "\n",
    "shared_lstm = LSTM(64)\n",
    "\n",
    "lstm_resume = shared_lstm(encoded_resume)\n",
    "lstm_job_desc = shared_lstm(encoded_job_desc)\n",
    "\n",
    "merged = Concatenate()([lstm_resume, lstm_job_desc])\n",
    "dense = Dense(64, activation='relu')(merged)\n",
    "dropout = Dropout(0.5)(dense)\n",
    "output = Dense(3, activation='softmax')(dropout)\n",
    "\n",
    "model = Model(inputs=[input_resume, input_job_desc], outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit([X_train_resume, X_train_job_desc], y_train, epochs=30, batch_size=32, validation_split=0.2)\n",
    "\n",
    "loss, accuracy = model.evaluate([X_test_resume, X_test_job_desc], y_test)\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
